{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNumZNeAu+hcvhT9XGVIF1s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e0e7269325144ad8619df8f9f551db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73192418554f4e728567b42bfaf00e1d",
              "IPY_MODEL_5251a33c37694ecdb96846918f87956f",
              "IPY_MODEL_7c76cc652a604504b5a7b8b08819f516"
            ],
            "layout": "IPY_MODEL_a4ae1ea92f5046cdb96ed32de180d3a1"
          }
        },
        "73192418554f4e728567b42bfaf00e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a0054d5e0704b2e94ec56b4358e02c2",
            "placeholder": "​",
            "style": "IPY_MODEL_2f0027fc15f34a6ea7a2ebb6e4baff84",
            "value": "model.safetensors: 100%"
          }
        },
        "5251a33c37694ecdb96846918f87956f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7807b52aca8466b8a6b081c8a17699d",
            "max": 989721256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7d7cf7d2b644cb98d907ddee23f88f7",
            "value": 989721256
          }
        },
        "7c76cc652a604504b5a7b8b08819f516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6660ffbe87d045cc9edf4597125806e2",
            "placeholder": "​",
            "style": "IPY_MODEL_ba03cadc1d194a3abfd8ae0f7b6a1a09",
            "value": " 990M/990M [00:09&lt;00:00, 125MB/s]"
          }
        },
        "a4ae1ea92f5046cdb96ed32de180d3a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a0054d5e0704b2e94ec56b4358e02c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f0027fc15f34a6ea7a2ebb6e4baff84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7807b52aca8466b8a6b081c8a17699d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7d7cf7d2b644cb98d907ddee23f88f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6660ffbe87d045cc9edf4597125806e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba03cadc1d194a3abfd8ae0f7b6a1a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chandan-devraj/Capstone-Project/blob/main/Indian_faces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests opencv-python-headless mediapipe pillow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmY7M0tE9oMN",
        "outputId": "aaa11917-4262-4b2a-9815-9499b257f7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.18 sounddevice-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import mediapipe as mp\n"
      ],
      "metadata": {
        "id": "ZlIKLF81Akp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pixabay API Key\n",
        "PIXABAY_API_KEY = \"27542215-1bcc2dba5b7791b910e679866\"\n",
        "\n",
        "# Mediapipe Setup\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "# Directory to store valid images\n",
        "os.makedirs(\"3\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "UKV23fc1-Q70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_images(query, num_images=50):\n",
        "    \"\"\"Fetch images from Pixabay API.\"\"\"\n",
        "    url = f\"https://pixabay.com/api/?key={PIXABAY_API_KEY}&q={query}&image_type=photo&per_page={num_images}\"\n",
        "    response = requests.get(url).json()\n",
        "    return response.get('hits', [])\n"
      ],
      "metadata": {
        "id": "7kO4fM02-T4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_valid_face(image_url):\n",
        "    \"\"\"Check if the image has a single, straight-looking face with both eyes, nose, and mouth visible.\"\"\"\n",
        "    try:\n",
        "        # Download the image\n",
        "        response = requests.get(image_url)\n",
        "        image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "        image_np = np.array(image)  # Convert to NumPy array\n",
        "\n",
        "        # Initialize Mediapipe face detection\n",
        "        with mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:\n",
        "            results = face_detection.process(cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "            # Check if exactly one face is detected\n",
        "            if not results.detections or len(results.detections) != 1:\n",
        "                return None  # Invalid image\n",
        "\n",
        "        # Initialize Mediapipe face mesh for landmarks\n",
        "        with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True) as face_mesh:\n",
        "            results = face_mesh.process(cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "            # Check if landmarks are detected\n",
        "            if not results.multi_face_landmarks:\n",
        "                return None  # Invalid image\n",
        "\n",
        "            # Extract landmarks\n",
        "            landmarks = results.multi_face_landmarks[0]\n",
        "            landmark_points = landmarks.landmark\n",
        "\n",
        "            # Ensure all landmarks are detected (we expect 468 landmarks)\n",
        "            if len(landmark_points) < 468:\n",
        "                return None  # Not all landmarks detected\n",
        "\n",
        "            # Check visibility of key facial features: both eyes, nose, and mouth\n",
        "            left_eye = landmark_points[33]  # Left eye index\n",
        "            right_eye = landmark_points[263]  # Right eye index\n",
        "            nose_tip = landmark_points[1]  # Nose tip index\n",
        "            mouth_left = landmark_points[13]  # Left mouth corner\n",
        "            mouth_right = landmark_points[14]  # Right mouth corner\n",
        "\n",
        "            # Check that both eyes are visible\n",
        "            if left_eye.visibility < 0.5 or right_eye.visibility < 0.5:\n",
        "                return None  # At least one eye is not visible\n",
        "\n",
        "            # Check that the nose is visible\n",
        "            if nose_tip.visibility < 0.5:\n",
        "                return None  # Nose is not visible\n",
        "\n",
        "            # Check that the mouth is visible\n",
        "            if mouth_left.visibility < 0.5 or mouth_right.visibility < 0.5:\n",
        "                return None  # Mouth is not visible\n",
        "\n",
        "            # Ensure eyes are horizontally aligned (for a straight face)\n",
        "            if abs(left_eye.y - right_eye.y) > 0.05:  # Tolerance for alignment\n",
        "                return None  # Face not straight-looking\n",
        "\n",
        "            # If all checks pass, return the valid image\n",
        "            return image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "w-e-Vxz_-oBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"7\", exist_ok=True)"
      ],
      "metadata": {
        "id": "QjrfV9G7Df3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_images(query, num_images=50):\n",
        "    \"\"\"Fetch and process images.\"\"\"\n",
        "    images = fetch_images(query, num_images)\n",
        "    valid_count = 0\n",
        "\n",
        "    for i, img_data in enumerate(images):\n",
        "        img_url = img_data.get('webformatURL')\n",
        "        if img_url:\n",
        "            valid_image = is_valid_face(img_url)\n",
        "            if valid_image:\n",
        "                valid_count += 1\n",
        "                valid_image.save(f\"7/face_{valid_count}.jpg\")\n",
        "                print(f\"Saved: face_{valid_count}.jpg\")\n",
        "\n",
        "    print(f\"Total valid images saved: {valid_count}\")\n",
        "\n",
        "# Run the process\n",
        "process_images(\"Portrait , straight lokking single Indian face with eyes nose nd mouth clearly visible\", num_images=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPHlHyCI-WQk",
        "outputId": "4d731560-b9b8-462a-998b-98c8cd1db560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: face_1.jpg\n",
            "Saved: face_2.jpg\n",
            "Saved: face_3.jpg\n",
            "Saved: face_4.jpg\n",
            "Saved: face_5.jpg\n",
            "Saved: face_6.jpg\n",
            "Saved: face_7.jpg\n",
            "Saved: face_8.jpg\n",
            "Saved: face_9.jpg\n",
            "Saved: face_10.jpg\n",
            "Saved: face_11.jpg\n",
            "Saved: face_12.jpg\n",
            "Total valid images saved: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PDD47HRrC8d8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9m-hT6PkC8oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Initialize mediapipe face detection and face mesh\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "# Function to check if all required landmarks are visible\n",
        "def is_valid_face(image_path):\n",
        "    \"\"\"Check if the image has a single, straight-looking face with all landmarks visible.\"\"\"\n",
        "    try:\n",
        "        # Open the image\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image_np = np.array(image)  # Convert to NumPy array\n",
        "\n",
        "        # Initialize Mediapipe face detection\n",
        "        with mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:\n",
        "            results = face_detection.process(cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "            # Check if exactly one face is detected\n",
        "            if not results.detections or len(results.detections) != 1:\n",
        "                return None  # Invalid image\n",
        "\n",
        "        # Initialize Mediapipe face mesh for landmarks\n",
        "        with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True) as face_mesh:\n",
        "            results = face_mesh.process(cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "            # Check if landmarks are detected\n",
        "            if not results.multi_face_landmarks:\n",
        "                return None  # Invalid image\n",
        "\n",
        "            # Extract landmarks\n",
        "            landmarks = results.multi_face_landmarks[0]\n",
        "            landmark_points = landmarks.landmark\n",
        "\n",
        "            # Ensure all landmarks are detected (we expect 468 landmarks)\n",
        "            if len(landmark_points) < 468:\n",
        "                return None  # Not all landmarks detected\n",
        "\n",
        "            # Check visibility of key facial features: both eyes, nose, and mouth\n",
        "            left_eye = landmark_points[33]  # Left eye index\n",
        "            right_eye = landmark_points[263]  # Right eye index\n",
        "            nose_tip = landmark_points[1]  # Nose tip index\n",
        "            mouth_left = landmark_points[13]  # Left mouth corner\n",
        "            mouth_right = landmark_points[14]  # Right mouth corner\n",
        "\n",
        "            # Check that both eyes are visible\n",
        "            if left_eye.visibility < 0.5 or right_eye.visibility < 0.5:\n",
        "                return None  # At least one eye is not visible\n",
        "\n",
        "            # Check that the nose is visible\n",
        "            if nose_tip.visibility < 0.5:\n",
        "                return None  # Nose is not visible\n",
        "\n",
        "            # Check that the mouth is visible\n",
        "            if mouth_left.visibility < 0.5 or mouth_right.visibility < 0.5:\n",
        "                return None  # Mouth is not visible\n",
        "\n",
        "            # Ensure eyes are horizontally aligned (for a straight face)\n",
        "            if abs(left_eye.y - right_eye.y) > 0.05:  # Tolerance for alignment\n",
        "                return None  # Face not straight-looking\n",
        "\n",
        "            # If all checks pass, return the valid image\n",
        "            return image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "    return None\n",
        "\n",
        "# Path to the folder containing images\n",
        "folder_path = '/content/7'  # Replace with your folder path\n",
        "\n",
        "# List to store valid images\n",
        "valid_images = []\n",
        "\n",
        "# Loop through all images in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(('.png', '.jpg', '.jpeg')):  # Only process image files\n",
        "        image_path = os.path.join(folder_path, filename)\n",
        "        print(f\"Processing {filename}...\")\n",
        "\n",
        "        valid_image = is_valid_face(image_path)\n",
        "\n",
        "        if valid_image:\n",
        "            valid_images.append(valid_image)\n",
        "            print(f\"{filename} is valid.\")\n",
        "        else:\n",
        "            print(f\"{filename} is not valid.\")\n",
        "\n",
        "# Print the number of valid images\n",
        "print(f\"Number of valid images: {len(valid_images)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGKRm_FVGpej",
        "outputId": "9758ef56-9e16-4799-a02b-03200acf3931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing face_1.jpg...\n",
            "face_1.jpg is not valid.\n",
            "Processing face_7.jpg...\n",
            "face_7.jpg is not valid.\n",
            "Processing face_8.jpg...\n",
            "face_8.jpg is not valid.\n",
            "Processing face_4.jpg...\n",
            "face_4.jpg is not valid.\n",
            "Processing face_12.jpg...\n",
            "face_12.jpg is not valid.\n",
            "Processing face_6.jpg...\n",
            "face_6.jpg is not valid.\n",
            "Processing face_11.jpg...\n",
            "face_11.jpg is not valid.\n",
            "Processing face_2.jpg...\n",
            "face_2.jpg is not valid.\n",
            "Processing face_9.jpg...\n",
            "face_9.jpg is not valid.\n",
            "Processing face_3.jpg...\n",
            "face_3.jpg is not valid.\n",
            "Processing face_10.jpg...\n",
            "face_10.jpg is not valid.\n",
            "Processing face_5.jpg...\n",
            "face_5.jpg is not valid.\n",
            "Number of valid images: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "luug1lS1GpnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Initialize mediapipe face detection and face mesh\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "# Pixabay API key and endpoint\n",
        "API_KEY = \"27542215-1bcc2dba5b7791b910e679866\"  # Replace with your Pixabay API Key\n",
        "PIXABAY_API_URL = \"https://pixabay.com/api/\"\n",
        "\n",
        "# Function to download image from a URL\n",
        "def download_image(image_url):\n",
        "    \"\"\"Download image from URL.\"\"\"\n",
        "    response = requests.get(image_url)\n",
        "    image = Image.open(BytesIO(response.content))\n",
        "    return image\n",
        "\n",
        "# Function to check if all required landmarks are visible\n",
        "def is_valid_face(image):\n",
        "    \"\"\"Check if the image has a single, straight-looking face with all landmarks visible.\"\"\"\n",
        "    try:\n",
        "        image_np = np.array(image)  # Convert to NumPy array\n",
        "\n",
        "        # Initialize Mediapipe face detection\n",
        "        with mp_face_detection.FaceDetection(min_detection_confidence=0.5) as face_detection:\n",
        "            results = face_detection.process(cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "            # Check if exactly one face is detected\n",
        "            if not results.detections or len(results.detections) != 1:\n",
        "                return False  # Invalid image\n",
        "\n",
        "        # Initialize Mediapipe face mesh for landmarks\n",
        "        with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True) as face_mesh:\n",
        "            results = face_mesh.process(cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "            # Check if landmarks are detected\n",
        "            if not results.multi_face_landmarks:\n",
        "                return False  # Invalid image\n",
        "\n",
        "            # Extract landmarks\n",
        "            landmarks = results.multi_face_landmarks[0]\n",
        "            landmark_points = landmarks.landmark\n",
        "\n",
        "            # Ensure all landmarks are detected (we expect 468 landmarks)\n",
        "            if len(landmark_points) < 468:\n",
        "                return False  # Not all landmarks detected\n",
        "\n",
        "            # Check visibility of key facial features: both eyes, nose, and mouth\n",
        "            left_eye = landmark_points[33]  # Left eye index\n",
        "            right_eye = landmark_points[263]  # Right eye index\n",
        "            nose_tip = landmark_points[1]  # Nose tip index\n",
        "            mouth_left = landmark_points[13]  # Left mouth corner\n",
        "            mouth_right = landmark_points[14]  # Right mouth corner\n",
        "\n",
        "            # Check that both eyes are visible\n",
        "            if left_eye.visibility < 0.5 or right_eye.visibility < 0.5:\n",
        "                return False  # At least one eye is not visible\n",
        "\n",
        "            # Check that the nose is visible\n",
        "            if nose_tip.visibility < 0.5:\n",
        "                return False  # Nose is not visible\n",
        "\n",
        "            # Check that the mouth is visible\n",
        "            if mouth_left.visibility < 0.5 or mouth_right.visibility < 0.5:\n",
        "                return False  # Mouth is not visible\n",
        "\n",
        "            # Ensure eyes are horizontally aligned (for a straight face)\n",
        "            if abs(left_eye.y - right_eye.y) > 0.05:  # Tolerance for alignment\n",
        "                return False  # Face not straight-looking\n",
        "\n",
        "            # If all checks pass, return valid\n",
        "            return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "    return False\n",
        "\n",
        "# Function to fetch images from Pixabay API\n",
        "def fetch_images_from_pixabay(query, num_images=50):\n",
        "    \"\"\"Fetch images from Pixabay based on search query.\"\"\"\n",
        "    params = {\n",
        "        \"key\": API_KEY,\n",
        "        \"q\": query,\n",
        "        \"image_type\": \"photo\",\n",
        "        \"per_page\": num_images\n",
        "    }\n",
        "    response = requests.get(PIXABAY_API_URL, params=params)\n",
        "    data = response.json()\n",
        "\n",
        "    # Get URLs of the images\n",
        "    image_urls = [hit[\"webformatURL\"] for hit in data[\"hits\"]]\n",
        "    return image_urls\n",
        "\n",
        "# Path to the folder to save valid images\n",
        "valid_images_folder = '/content/8'\n",
        "os.makedirs(valid_images_folder, exist_ok=True)\n",
        "\n",
        "# Fetch images based on search query (e.g., \"people face\")\n",
        "image_urls = fetch_images_from_pixabay(\"Indian face\", num_images=50)\n",
        "\n",
        "valid_image_count = 0\n",
        "\n",
        "# Process each image URL\n",
        "for image_url in image_urls:\n",
        "    print(f\"Processing image: {image_url}...\")\n",
        "\n",
        "    # Download the image\n",
        "    image = download_image(image_url)\n",
        "\n",
        "    # Check if the image has a valid face\n",
        "    if is_valid_face(image):\n",
        "        # Save valid image\n",
        "        image_name = os.path.join(valid_images_folder, f\"valid_image_{valid_image_count + 1}.jpg\")\n",
        "        image.save(image_name)\n",
        "        print(f\"Valid image saved as {image_name}\")\n",
        "        valid_image_count += 1\n",
        "    else:\n",
        "        print(\"Invalid image, discarded.\")\n",
        "\n",
        "# Final output\n",
        "print(f\"Total valid images: {valid_image_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JedpQ2XJHnUj",
        "outputId": "cf3f4b4d-daa3-4211-b94d-6714740b58b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing image: https://pixabay.com/get/g171e0869912b85fe7d233bad30c5f619a10cb99cfdd16eac8be6b0cff95379843ae6a415ab6efbcb8039b3602445293f_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g981625ffea2608b1954e662208e26756cbae38a9feed932e76056fe60ace255b37c0ac466915f176aa539977ded8bf76cfa6d33b75da3eda2720d73fc2d45a70_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g7432e0e3967a4079f385d56971999c07d1fcc127cbcb1d2878d5322ec1d6dac54721fd6d57584da52520fc20b74f1d6a_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g0f33986ec9854e1dd9b2e00053b595f75eb7ff6f81364a1f75ea7ebe6d0fae1e666a1f035ad9abebeca97d1cca2985de2305552e71a40a7d301f700535ebdb40_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/gb84d90f9747579b4463ad136d6871fcd5aadafc41d253bed286cc3b5d2e0934029cdb20551bd276818a75536677d414af065fd01e973ca49f73c0d484bd193e4_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/gf2b0804220e108ff47ce547843afea8dbc8946583a7a9033f1f1aa8bcb69470c001e96eb5cb5152ab072054fa1465e5ee808d548282f48e68ebb6574d41cd161_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/ga7c0e01972a4d4a0e0af22d61822b5ab6a990bf8263fdaafaae736a5a42ba173bd0cba583a86e279b3c1e1bc18eb76582b910555cdbdc14161c6fa57712dfd2e_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/ge1d432ad41f227cab652c539333b1d7fe60c39810d1e0e054924f3efeec361e2925fbd1b9baa8df48d60979ccdfd1b57fc09e06f8ce2b2b5662986b452d19369_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/gfc4cc6d18ae88c04e415f263a1341d53722ae3970d513ab2860691408dd4963e137d5be38155d5446853f029d779fa7f71e323a04e9d66fbe6dbfbc29b2939f2_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g8b69403e61cc00d32202ee3f24054185b74668d7596b790e8591217bea71019c4c9e3644959161c70f3c3dc3e05bb725493cf894f7b8d57416682348b277eeb6_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/ged54656f69fc0cb35fc38aac6e7494428948e9b5d3aead6a71019e14db2b5101c05ed88d614abe0c463b63192318b26eb18676a1e6712aeab8f0b3ad2345d485_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g95d1ec743b68c2715dc1ebc58faf15d126018b298f638ec0c3de371559b5e94455bd3e5dda7873024211d9ee6425a46e13b4874319bbb1f4cfe9d8d0120e2089_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g505dd650ee7d1206639b8f20bf44556625889421e788653c6c92115aa9d3d2399dac86ddd2a88e097025f36bf341da88018294885a5e63359210cbf01aa7d928_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g52391155b38432a82a35977eb78e900c188224311beea3307fda36783f090d40c8bd4af634d3b379fa6477cb32f4967b0cce57fe7b520cb9510ec32427208f93_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g845a1fa437d9bbfd56f707012cf68981bacbfef99747807dcce286cf29bc2eb5501282a453e8533ecb3669a66b90cb9b48495e60c3d3ea21480e43e9fa02806e_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g9be09b0e9fb8b7fca568559fe0f389d5de937fd6cf43f5dd209ce7c5ca4ce7e23af16ec086a87f9acaa653cabb2ca81e7c3212885176b629fda7772648c4ebda_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g96b52d7fe06b497550dcaaf3e9dd059ec33f54ebef15cf5143faf2e93b6aeb51fed2220eb548ea40d91236cc6d8587b6cb4c08058149e883e9e44311908ff696_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g027c60b33918e10dc93e6d81f300aec1cc348d7be2d477aebe7c3e6d18fcc636cb3cf288a0a1fcc41ac2eec57871121bef2b2dffc2af3dd83fe24f8562c41fb2_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g9906ce88d6ccd8b7cdb22a7e7b5e387d0010c650a9db400429703b2ab5dd540d41d1a48ee3d1c167a80713b892835b12af195fe51d473f02928e680ddf0ec1f0_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g2956ae7320e529f78b033d459b3c356260eb5a75132297757ebe9292b8ce851124fd272278590ada3b30a6d2dc283e72bcc22df640e8f14ba42a9c25701fbfd7_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/gb94d320354422e81eac856d7ac46d1c9409c9ce1f6ad80c5f9478a5252d6a5effa5ef35b2d5a1bc0779e6c9e150d614a_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g8506c72f2757628bcf6e672150591d4a40197463c1c5cb4d4e01061d69d40fea40db869b92a358b8ce8b8624c7eba904c69772328189d571597a17603b1bfb45_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/gd5845c9b549b387f629131a608a6fad5bb737fb4bc5be6ee0cf5a2120916d11095495c0ae0c6ae5e906cbda5a84c43dc_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g8452fb658cec3410dc779f9c1401e2381737103d55ac6dca81cbde54cde7ef7a0f7c6e56edab7a382cab97f6447d5612373b74952e74914281f4bee5a5c138ac_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g809673ee01b8440dcfb8eb2609740f042807d8359b44c15d600be885236ef735f431df835be228d43680431db93be202711bd4fd426f314c0a4e45118b43ebfa_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g7f3b8c6e94160dbc666f61d117bd2173099f2a7811ccb8918dd5d09fe556e669f311cf113927a59b77ab5c60afb2fc46458f8429cf151fd7078d75ec276546ec_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/ga62072ee56ebc8730aed71c8161558133b7695dcfda1d34a5a42ac5fd19d03c0da44670300fcaec1df63ab19141a48dd2ac40977819d097fdb7a704b9683f8ff_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g43430b122468817d2f42d8d6e3e317ab57ad21b28e71350b9c3d8aed04261f9eb422ae732de4bf118afffe6dce8a6ea0_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/gd957185b44c22552bd1d756704e5c8e4c8fd522072772b94ed04a86486df405ffc60b70e995d22a35c872a9cba1e7ab899e3f887623c45d26d832a456ad2b1df_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g506a51ce5b80f6b40e703c18fb75c949073f611cb479874d7153d8a4018b2adfcc6fd4ea5594988408eb5085f33ab13073aed0ab1a22c55ca4cde874bf88f062_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/gf4e7646c5db8749871af800e012d63d62b2a349cb23eeacb0dda9e8df69717e6d22585f2fa164fda809867101f25796631ec6a21d91af82eda6729a7d6ff0cc5_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g848b7803d9848c2bffe7baecd9380f1f822de4a34779b75ed59c2514d313119b7a3ae29c03cfc3c96a2cfb5181a52ca915f463661a27ca62e91413f24752e434_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g3d998cb622c18eca80af60fabb4670020c383729e72e93e78bd759c124669554df6f81812a76ee257d97eaf50f0c3d1b_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/ga947354a5a31856e2d0110003835f73685b122e07d7e8756b4bb108e2775cc4353dc409f5aeb920f615db9336649277b120313563242426f86c98b8c25987d2a_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g72a8e98a2f86ea2cfa1f5651c4cea735613323c1690f75ef014519914c832f5a1bf49f366ed667d131fb2ebeedee7efbab551b262530ee0d6cbdef755ffcbd4f_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/ge9e22343fa9a11fb5f73735e64466f67f782432eed5527fbc3853c76c9b6a4e76a9cc26f20c8103e200f85bae56ce385_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g3f85ad5b1da1dc307dd65f0116318543014d276bb6c92b447987c65d84b4a64e7507d86a8b6231a2d69017c45453d066aa905c436dfe438ded45e69d239f158d_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g8d1dc0703e5e4736df60a90780392476bea6504fc8a69bdd2388c1bc305bd945ed7a79071775c204b017f78e96d18a70d48332c44affcae46d0bf9647e1c47ea_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/gabbb44de604c8f1b526d2dff412c91c1f1f39f63de1de9a1e69bb5d1d1c0372574c89faf5c95fcb020bdb7021cab00103b5413535a64b267f439103997cb8bad_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g04e4ed9ed863ff85006800b16194cd07a677c768427fb8e7e94c7228f220a6a557332b5c00981f6672b773c4b64ffe22de698b8137aa0a42ed313a7a0ec15750_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g542dcbd4377d3b626c583f9929b4ff3e9ebbef96305b389c6d4c6f4498bba1142f04146a53041e552d2b0396b6281ab827ccf1bc91e27a3a866cd259dd0ce807_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g46f0ee5ac83cdb2d9439c4032d1ba4cc41960bf83a0154e821a72972d0bd1ccbfe0ec01cb55a6c20c01c41d3ffe7ac21bc22ec1fe305d022e7dce968379022f4_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/gf52d6be64a60db80ed54b41066ab358c3d530ee94cafcf1aa219954804df56fb3917fc3785642637d45785943651e868669a1a1d427728231497733aae0b3c20_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/ge0ecca04f39827c296b274776f8ee6c366b9b4fefede41dfbc6ce3dd11b94a0469e7f9cff347aed6e01a964d0d6f66e42509639354a2df705800f7e435c55852_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g49eb899890cc4139673c3a0b42911dbafd7b8e5a29d710a29babd14fb8520f36fe4d1705c7d7c1d66dc8a77e3f538e0494cbddadc7c988f8f13e60c74452bfc8_640.png...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/gc71113289dab2567025acdece5370c605f1bbc01320bb9def732c1144979a8c00e76e941b3e4089fe19711c06eaf6f360dcc9d70726448d2405d4d8847d17f03_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/gc117f6843ac264778a8e05615ff6d426ddd80903f6e464ba59ba2632bacb4ada89e5f8a54ef1d15acf5e09a34730d22f_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/ge59539b32dcb8c76367ea5653e86597e009584375d656c25fa9e681c2d24644f4871a42fe1ea7f666854660d83f1a5c2_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g06c50f755a2cdc8b8d348ba443090c0b06772c0b52029cc08820aebdbc8c692949255f2dc45729d08348c962d371fadd1d84fd304d4f18ff533e0eef3d86a1cb_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Processing image: https://pixabay.com/get/g6b581d4982e60c6eeb5d5aa0fdc026c81ced21fab1f32549e9a94602cdadc7eae7aa32428ab67fc3e8a444ba2b760f4deebfd96e58ed94050b162d2642bf6639_640.jpg...\n",
            "Invalid image, discarded.\n",
            "Total valid images: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BeTcZ9oJHnbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"2\", exist_ok=True)"
      ],
      "metadata": {
        "id": "rnFfGucXAAvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, img_data in enumerate(images):\n",
        "    img_url = img_data.get('webformatURL')\n",
        "    if img_url:\n",
        "        valid_image = is_valid_face(img_url)\n",
        "        if valid_image:\n",
        "            valid_image.save(f\"2/face_{i+1}.jpg\")\n",
        "            print(f\"Saved: face_{i+1}.jpg\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bZZ1nyN-ZVc",
        "outputId": "051c1029-ea6b-420e-9fcd-0e4330f7f098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: face_1.jpg\n",
            "Saved: face_2.jpg\n",
            "Saved: face_3.jpg\n",
            "Saved: face_7.jpg\n",
            "Saved: face_8.jpg\n",
            "Saved: face_9.jpg\n",
            "Saved: face_10.jpg\n",
            "Saved: face_17.jpg\n",
            "Saved: face_19.jpg\n",
            "Saved: face_20.jpg\n",
            "Saved: face_23.jpg\n",
            "Saved: face_24.jpg\n",
            "Saved: face_25.jpg\n",
            "Saved: face_26.jpg\n",
            "Saved: face_31.jpg\n",
            "Saved: face_32.jpg\n",
            "Saved: face_34.jpg\n",
            "Saved: face_35.jpg\n",
            "Saved: face_37.jpg\n",
            "Saved: face_41.jpg\n",
            "Saved: face_44.jpg\n",
            "Saved: face_46.jpg\n",
            "Saved: face_47.jpg\n",
            "Saved: face_48.jpg\n",
            "Saved: face_49.jpg\n",
            "Saved: face_50.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Load BLIP model and processor\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "# Path to the folder containing images\n",
        "image_dir = \"/content/2\"  # Update this to the correct directory\n",
        "\n",
        "# Create a dictionary to store captions\n",
        "captions = {}\n",
        "\n",
        "# Loop through each image in the folder\n",
        "for img_file in os.listdir(image_dir):\n",
        "    img_path = os.path.join(image_dir, img_file)  # Combine folder path and file name\n",
        "\n",
        "    # Ensure the path is a valid file and ends with a supported image extension\n",
        "    if os.path.isfile(img_path) and img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        try:\n",
        "            # Open the image\n",
        "            image = Image.open(img_path)\n",
        "\n",
        "            # Generate caption\n",
        "            inputs = processor(images=image, return_tensors=\"pt\")\n",
        "            outputs = model.generate(**inputs)\n",
        "            caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Save the caption\n",
        "            captions[img_file] = caption\n",
        "            print(f\"Caption for {img_file}: {caption}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_file}: {e}\")\n",
        "\n",
        "# Save all captions to a text file\n",
        "with open(\"captions.txt\", \"w\") as f:\n",
        "    for img, caption in captions.items():\n",
        "        f.write(f\"{img}: {caption}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555,
          "referenced_widgets": [
            "3e0e7269325144ad8619df8f9f551db0",
            "73192418554f4e728567b42bfaf00e1d",
            "5251a33c37694ecdb96846918f87956f",
            "7c76cc652a604504b5a7b8b08819f516",
            "a4ae1ea92f5046cdb96ed32de180d3a1",
            "3a0054d5e0704b2e94ec56b4358e02c2",
            "2f0027fc15f34a6ea7a2ebb6e4baff84",
            "d7807b52aca8466b8a6b081c8a17699d",
            "e7d7cf7d2b644cb98d907ddee23f88f7",
            "6660ffbe87d045cc9edf4597125806e2",
            "ba03cadc1d194a3abfd8ae0f7b6a1a09"
          ]
        },
        "id": "LE4fwj1xA6pp",
        "outputId": "26554370-57b2-4fb7-b4b8-0b8199d392e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e0e7269325144ad8619df8f9f551db0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caption for face_20.jpg: a woman sitting on a wall in the street\n",
            "Caption for face_1.jpg: a woman in a red vest and black shirt\n",
            "Caption for face_48.jpg: a young girl smiles for the camera\n",
            "Caption for face_32.jpg: a woman with a pink eye makeup\n",
            "Caption for face_47.jpg: a woman with yellow face paint\n",
            "Caption for face_35.jpg: a girl with long hair and bangs\n",
            "Caption for face_7.jpg: a young boy in a white hat\n",
            "Caption for face_41.jpg: two young boys sitting on the ground\n",
            "Caption for face_44.jpg: a bride in a traditional outfit\n",
            "Caption for face_8.jpg: a bride in a red bridal\n",
            "Caption for face_25.jpg: a woman in a red dress sitting on a yellow vehicle\n",
            "Caption for face_46.jpg: a woman in a native costume holding a spear\n",
            "Caption for face_37.jpg: a young girl in the streets of the old city\n",
            "Caption for face_23.jpg: a woman in an orange dress standing in front of a blue background\n",
            "Caption for face_34.jpg: a young girl with fr fr fr fr fr fr fr fr fr fr fr fr fr fr fr\n",
            "Caption for face_2.jpg: a man in a red tuk hat\n",
            "Caption for face_17.jpg: a woman with red hair and blue eyes\n",
            "Caption for face_19.jpg: a young boy holding a wooden stick in his hand\n",
            "Caption for face_9.jpg: a girl with long hair and a leather jacket\n",
            "Caption for face_49.jpg: a woman with long brown hair and a black background\n",
            "Caption for face_31.jpg: a woman in a black top and a green background\n",
            "Caption for face_3.jpg: a man in a hat and vest sitting on a bench\n",
            "Caption for face_50.jpg: a woman sitting on the ground in front of a brick wall\n",
            "Caption for face_10.jpg: a young woman with long brown hair and blue and white striped shirt\n",
            "Caption for face_24.jpg: an old woman sitting on a bench in the park\n",
            "Caption for face_26.jpg: a man standing in front of a wooden wall\n"
          ]
        }
      ]
    }
  ]
}